{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# this cell creates a set of files used by the examples below. On readthedocs, this cell is hidden.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import xarray as xr\n",
    "from scipy.interpolate import interp1d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# time vector on 4 years\n",
    "times = pd.date_range('2000-01-01', '2003-12-31', freq='D')\n",
    "# temperature data as seasonal cycle -18 to 18\n",
    "tas = xr.DataArray(-18 * np.cos(2 * np.pi * times.dayofyear / 365),\n",
    "                   dims=('time',), coords={'time': times}, name ='tas',\n",
    "                   attrs={'units': 'degC', 'standard_name': 'air_temperature', \n",
    "                          'long_name': 'Mean air temperature at surface'})\n",
    "\n",
    "# write 10 members adding cubic-smoothed gaussian noise of wavenumber 43 and amplitude 20\n",
    "# resulting temp will oscillate between -18 and 38\n",
    "for i in range(10):\n",
    "    tasi = tas + 20 * interp1d(np.arange(43), np.random.random((43,)), kind='quadratic')(np.linspace(0, 42, tas.size))\n",
    "    tasi.name = 'tas'\n",
    "    tasi.attrs.update(tas.attrs)\n",
    "    tasi.attrs['title'] = f'tas of member {i:02d}'\n",
    "    tasi.to_netcdf(f'ens_tas_m{i}.nc')\n",
    "\n",
    "# Create 'toy' criteria selection data\n",
    "np.random.normal(loc=3.5, scale=1.5, size=50)\n",
    "#crit['delta_annual_tavg']\n",
    "np.random.seed(0)\n",
    "test = xr.DataArray(np.random.normal(loc=3, scale=1.5, size=100), dims=['realization']).assign_coords(horizon='2041-2070')\n",
    "test = xr.concat((test,xr.DataArray(np.random.normal(loc=5.34, scale=2, size=100), dims=['realization']).assign_coords(horizon='2071-2100')), dim='horizon')\n",
    "ds_crit = xr.Dataset()\n",
    "ds_crit['delta_annual_tavg'] = test\n",
    "test = xr.DataArray(np.random.normal(loc=5, scale=5, size=100), dims=['realization']).assign_coords(horizon='2041-2070')\n",
    "test = xr.concat((test,xr.DataArray(np.random.normal(loc=10, scale=8, size=100), dims=['realization']).assign_coords(horizon='2071-2100')), dim='horizon')\n",
    "ds_crit['delta_annual_prtot'] = test\n",
    "\n",
    "test = xr.DataArray(np.random.normal(loc=0, scale=3, size=100), dims=['realization']).assign_coords(horizon='2041-2070')\n",
    "test = xr.concat((test,xr.DataArray(np.random.normal(loc=2, scale=4, size=100), dims=['realization']).assign_coords(horizon='2071-2100')), dim='horizon')\n",
    "ds_crit['delta_JJA_prtot'] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles\n",
    "=========\n",
    "\n",
    "An important aspect of climate models is that they are run multiple times with some initial perturbations to see how they replicate the natural variability of the climate. Through [xclim.ensembles](../api.rst#module-xclim.ensembles), xclim provides an easy interface to compute ensemble statistics on different members. Most methods perform checks and conversion on top of simpler `xarray` methods, providing an easier interface to use.\n",
    "\n",
    "### create_ensemble\n",
    "Our first step is to create an ensemble. This methods takes a list of files defining the same variables over the same coordinates and concatenates them into one dataset with an added dimension `realization`.\n",
    "\n",
    "Using `xarray` a very simple way of creating an ensemble dataset would be :\n",
    "```python\n",
    "open_mfdataset(files, concat_dim='realization') \n",
    "```\n",
    "\n",
    "However, this is only successful when the dimensions of all the files are identical AND only if the calendar type of each netcdf file is the same\n",
    "\n",
    "xclim's `create_ensemble()` method overcomes these constraints selecting the common time period to all files and assigns a standard calendar type to the dataset. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Input netcdf files still require equal spatial dimension size (e.g. lon, lat dimensions). <br>\n",
    "If input data contains multiple cftime calendar types they must not be at daily frequency.\n",
    "\n",
    "</div>\n",
    "\n",
    "Given files all named `ens_tas_m[member number].nc`, we use `glob` to get a list of all those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xclim as xc\n",
    "import xarray as xr\n",
    "# Set display to HTML sytle (for fancy output)\n",
    "xr.set_options(display_style='html', display_width=50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from xclim import ensembles\n",
    "\n",
    "ens = ensembles.create_ensemble(glob.glob('ens_tas_m*.nc')).load()\n",
    "ens.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['figure.figsize'] = (13, 5)\n",
    "ens.tas.plot(hue='realization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.tas  # Attributes of the first dataset to be opened are copied to the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble statistics\n",
    "Beyond creating ensemble dataset the `xclim.ensembles` module contains functions for calculating statistics between realizations\n",
    "\n",
    "**Ensemble mean, standard-deviation, max & min**\n",
    "\n",
    "In the example below we use xclim's `ensemble_mean_std_max_min()` to calculate statistics across the 10 realizations in our test dataset. Output variables are created combining the original variable name `tas` with addtional ending indicating the statistic calculated on the realization dimension : `_mean`, `_stdev`, `_min`, `_max`\n",
    "\n",
    "The resulting output now contains 4 derived variables from the original single variable in our ensemble dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_stats = ensembles.ensemble_mean_std_max_min(ens)\n",
    "ens_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble percentiles\n",
    "\n",
    "Here we use xclim's `ensemble_percentiles()` to calculate percentile values across the 10 realizations. \n",
    "The output has now a `percentiles` dimension instead of `realization`. Split variables can be created instead, by specifying `split=True` (the variable name `tas` will be appended with `_p{x}`). Compared to numpy's `percentile()` and xarray's `quantile()`, this method handles more efficiently dataset with invalid values and the chunking along the realization dimension (which is automatic when dask arrays are used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ens_perc = ensembles.ensemble_percentiles(ens, values=[15, 50, 85], split=False)\n",
    "ens_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(ens_stats.time.values, ens_stats.tas_min, ens_stats.tas_max, alpha=0.3, label='Min-Max')\n",
    "ax.fill_between(ens_perc.time.values, ens_perc.tas.sel(percentiles=15), ens_perc.tas.sel(percentiles=85), alpha=0.5, label='Perc. 15-85')\n",
    "ax._get_lines.get_next_color()  # Hack to get different line\n",
    "ax._get_lines.get_next_color()\n",
    "ax.plot(ens_stats.time.values, ens_stats.tas_mean, linewidth=2, label='Mean')\n",
    "ax.plot(ens_perc.time.values, ens_perc.tas.sel(percentiles=50), linewidth=2, label='Median')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ensemble Reduction techniques\n",
    "`xclim.ensembles` provides means of reducing the number of candidates in a sample to get a reasonable and representative spread of outcomes using a reduced number of candidates. By reducing the number of realizations in a strategic manner, we can significantly reduce the number of relizations that are considered, while maintaining statistical representation of original dataset. This is particularly useful when computation power or time is a factor.\n",
    "\n",
    "**Selection Criteria** \n",
    "ADD TEXT HERE - pretend delta values IN THIS CASE WE HAVE A TOTAL OF 6 CRITERIA (3 delta variables with 2 horizons). We want to reduce the number of runs while still covering uncertainty in the 6 criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "ds_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for h in ds_crit.horizon:\n",
    "    ax.scatter(ds_crit.sel(horizon=h).delta_annual_tavg, ds_crit.sel(horizon=h).delta_annual_prtot,\n",
    "            ds_crit.sel(horizon=h).delta_JJA_prtot,label=f\"delta {h.values}\")\n",
    "\n",
    "ax.set_xlabel('delta_annual_tavg (C)')\n",
    "ax.set_ylabel('delta_annual_prtot (%)')\n",
    "ax.set_zlabel('delta_JJA_prtot (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Ensemble reduction techniques require a 2D array with dimensions of `criteria` and `realization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create 2d xr.DataArray containincg criteria values\n",
    "crit=None\n",
    "for h in ds_crit.horizon:\n",
    "    for v in ds_crit.data_vars:\n",
    "        if crit is None:\n",
    "            crit = ds_crit[v].sel(horizon=h)\n",
    "        else:\n",
    "            crit = xr.concat((crit, ds_crit[v].sel(horizon=h)), dim='criteria')\n",
    "crit.name= 'criteria'\n",
    "crit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **K-Means reduce ensemble**\n",
    "\n",
    "The `kmeans_reduce_ensemble` works by grouping realizations into sub-groups based on the provided critera and retaining a representative `realization` per sub-group\n",
    "* Example using `method = n_clusters`  \n",
    "* The function  returns the `ids` of the selected realizations\n",
    "* In this example we reduce the original 100 realizations to n=25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, cluster, fig_data = ensembles.kmeans_reduce_ensemble(data=crit, method={'n_clusters':25}, random_state=42, make_graph=True)\n",
    "ds_crit.isel(realization = ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the distribution of the selection versus the original ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for h in ds_crit.horizon:\n",
    "\n",
    "    ax.scatter(ds_crit.sel(horizon=h,realization=ids).delta_annual_tavg, ds_crit.sel(horizon=h, realization=ids).delta_annual_prtot ,\n",
    "            ds_crit.sel(horizon=h,realization=ids).delta_JJA_prtot,label=f\"delta {h.values} - selected\")\n",
    "\n",
    "ax.set_xlabel('delta_annual_tavg (C)')\n",
    "ax.set_ylabel('delta_annual_prtot (%)')\n",
    "ax.set_zlabel('delta_JJA_prtot (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function optionally produces a data dictionary for figure production of the associated R² profile. \n",
    "The function`ensembles.plot_rsqprofile` provides plotting for evaluating the proportion of total variance in climate realizations that is covered by the selection.  In this case ~78% of the total variance in original ensemble is covered by the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles.plot_rsqprofile(fig_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can use `method = {'rsq_cutoff':Float}` or `method = {'rsq_optimize':None}`\n",
    "* For example with `rsq_cutoff` we instead find the number of realizations needed to cover the provided R2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1, cluster1, fig_data1 = ensembles.kmeans_reduce_ensemble(data=crit, method={'rsq_cutoff':0.85}, random_state=42, make_graph=True)\n",
    "ensembles.plot_rsqprofile(fig_data1)\n",
    "ds_crit.isel(realization=ids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
